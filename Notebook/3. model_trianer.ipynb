{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Pred_maintainance-Project\\\\Notebook'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Pred_maintainance-Project'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.exception import CustomException\n",
    "from src.logger import logging\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(X_train, y_train,X_test,y_test,models,param):\n",
    "    try:\n",
    "        report = {}\n",
    "\n",
    "        for i in range(len(list(models))):\n",
    "            model = list(models.values())[i]\n",
    "            para=param[list(models.keys())[i]]\n",
    "\n",
    "            gs = GridSearchCV(model,para,cv=3)\n",
    "            gs.fit(X_train,y_train) \n",
    "\n",
    "            model.set_params(**gs.best_params_)\n",
    "            model.fit(X_train,y_train)\n",
    "\n",
    "            #model.fit(X_train, y_train)  # Train model\n",
    "\n",
    "            y_train_pred = model.predict(X_train)\n",
    "\n",
    "            y_test_pred = model.predict(X_test)\n",
    "\n",
    "            train_model_score = r2_score(y_train, y_train_pred)\n",
    "\n",
    "            test_model_score = r2_score(y_test, y_test_pred)\n",
    "\n",
    "            report[list(models.keys())[i]] = test_model_score\n",
    "\n",
    "        return report\n",
    "\n",
    "    except Exception as e:\n",
    "        raise CustomException(e, sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(X_train, y_train, X_test, y_test, models,param):\n",
    "    try:\n",
    "        report = {} #Creating Dict report\n",
    "        logging.info(\"Creating model report\")\n",
    "        for i in range(len(models)):\n",
    "            model = list(models.values())[i] #Listed all models\n",
    "            logging.info(\"Model Listd in Dictionary\")\n",
    "            para=param[list(models.keys())[i]]\n",
    "            \n",
    "            \n",
    "            \n",
    "            gs = GridSearchCV(model,para,cv=3)\n",
    "            gs.fit(X_train,y_train)\n",
    "\n",
    "            model.set_params(**gs.best_params_)\n",
    "            model.fit(X_train,y_train)\n",
    "\n",
    "            logging.info(f\"{model} trained\")\n",
    "            \n",
    "            #Predicting value\n",
    "            y_test_pred = model.predict(X_test)\n",
    "            logging.info(f\"{model} predicted\")\n",
    "            \n",
    "            #getting accuracy score\n",
    "            test_model_score = r2_score(y_test, y_test_pred)\n",
    "            logging.info(f\"{model} accuracy score generated\")\n",
    "            \n",
    "            report[list(models.keys())[i]] = test_model_score\n",
    "            logging.info(\"Report generated\")\n",
    "            \n",
    "        return report\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.info(\"Exception as model training step\")\n",
    "        raise CustomException(e, sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_object(file_path, obj):\n",
    "    \n",
    "    try:\n",
    "        dir_path = os.path.dirname(file_path)\n",
    "        \n",
    "        os.makedirs(dir_path, exist_ok = True)\n",
    "        \n",
    "        with open(file_path, \"wb\") as file_obj:\n",
    "            pickle.dump(obj, file_obj)\n",
    "                   \n",
    "    except Exception as e:\n",
    "        raise CustomException(e, sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelTrainerConfig:\n",
    "    trained_model_file_path = os.path.join(\"artifacts\", \"model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(self):\n",
    "        self.model_trainer_config=ModelTrainerConfig()\n",
    "        \n",
    "    def initiate_model_training(self, train_array, test_array):\n",
    "        try:\n",
    "            #Separating Train & test array\n",
    "            X_train, y_train, X_test, y_test = (\n",
    "                train_array[:,:-1],\n",
    "                train_array[:, -1],\n",
    "                test_array[:, :-1],\n",
    "                test_array[:, -1]\n",
    "            )\n",
    "            \n",
    "            models = {\n",
    "                \n",
    "                \"LinearRegression\" : LinearRegression(),\n",
    "                \"SVR\" : SVR(),\n",
    "                \"RandomForest\" : RandomForestRegressor(),\n",
    "                \"KNN\" : KNeighborsRegressor(),\n",
    "                \"DecisionTree\" : DecisionTreeRegressor(),\n",
    "                \"GradientBoosting\" : GradientBoostingRegressor()\n",
    "            }\n",
    "            \n",
    "            params = {\n",
    "                \n",
    "                \"LinearRegression\" : {},\n",
    "                \n",
    "                \"SVR\" : {\n",
    "                    # 'epsilon': [0.1, 0.2],\n",
    "                    # 'kernel': ['linear', 'poly'],\n",
    "                },\n",
    "                \n",
    "                \"RandomForest\" :{\n",
    "                    \n",
    "                    # 'criterion':['squared_error', 'absolute_error'],                 \n",
    "                    # 'max_features':['sqrt','log2'],\n",
    "                },\n",
    "                \n",
    "                \"KNN\" : {\n",
    "                    \n",
    "                    # 'n_neighbors' : [5, 7],\n",
    "                    # 'weights' : ['uniform', 'distance'],\n",
    "                },\n",
    "                \n",
    "                \"DecisionTree\" : {\n",
    "                    # 'criterion' : ['absolute_error', 'poisson'],\n",
    "                    # 'max_features':['sqrt','log2']\n",
    "                },\n",
    "                \n",
    "                \"GradientBoosting\" : {\n",
    "                    \n",
    "                    # 'loss':['squared_error', 'absolute_error'],\n",
    "                    # 'criterion':['squared_error', 'friedman_mse'],\n",
    "                }\n",
    "                \n",
    "                \n",
    "            }\n",
    "            \n",
    "            model_report:dict=evaluate_model(X_train, y_train, X_test, y_test, models,params)\n",
    "            print(model_report) \n",
    "            print(\"\\n**********\")\n",
    "            logging.info(f\"Model Report : {model_report}\")\n",
    "            \n",
    "            best_model_score = max(sorted(model_report.values()))\n",
    "            logging.info(\"Model score sorted\")\n",
    "            \n",
    "            #finding best model name\n",
    "            best_model_name = list(model_report.keys())[\n",
    "                list(model_report.values()).index(best_model_score)\n",
    "            ]\n",
    "            logging.info(\"Best model name has been found\")\n",
    "            \n",
    "            best_model = models[best_model_name]\n",
    "            print(f\"Best Model is {best_model_name} with accuracy : {best_model_score}\")\n",
    "            print(\"\\n*****\")\n",
    "            logging.info(f\"Best Model is {best_model_name} with accuracy : {best_model_score}\")\n",
    "            \n",
    "            save_object(   \n",
    "                file_path = self.model_trainer_config.trained_model_file_path, #storing file path\n",
    "                obj = best_model\n",
    "            )\n",
    "            logging.info(\"Best model saved as pkl file\")\n",
    "            \n",
    "\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from src.components.data_ingestion import DataIngestion\n",
    "#from src.components.data_transformation import DataTransformation\n",
    "\n",
    "from src.predictive_maintenance.components.data_ingestion import  DataIngestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.predictive_maintenance.components.data_transformation import DataTransformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Pred_maintainance-Project\\venv\\lib\\logging\\__init__.py\", line 1079, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"c:\\Pred_maintainance-Project\\venv\\lib\\logging\\__init__.py\", line 923, in format\n",
      "    return fmt.format(record)\n",
      "  File \"c:\\Pred_maintainance-Project\\venv\\lib\\logging\\__init__.py\", line 659, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"c:\\Pred_maintainance-Project\\venv\\lib\\logging\\__init__.py\", line 363, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"c:\\Pred_maintainance-Project\\venv\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"c:\\Pred_maintainance-Project\\venv\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Pred_maintainance-Project\\venv\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Pred_maintainance-Project\\venv\\lib\\site-packages\\traitlets\\config\\application.py\", line 1046, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Pred_maintainance-Project\\venv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Pred_maintainance-Project\\venv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Pred_maintainance-Project\\venv\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Pred_maintainance-Project\\venv\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Pred_maintainance-Project\\venv\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Pred_maintainance-Project\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Pred_maintainance-Project\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Pred_maintainance-Project\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Pred_maintainance-Project\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Pred_maintainance-Project\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Pred_maintainance-Project\\venv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Pred_maintainance-Project\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Pred_maintainance-Project\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Pred_maintainance-Project\\venv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Pred_maintainance-Project\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Pred_maintainance-Project\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Pred_maintainance-Project\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_3712\\1765588582.py\", line 4, in <module>\n",
      "    train_data, test_data = data_ingestion.initiate_data_ingestion()\n",
      "  File \"c:\\Pred_maintainance-Project\\src\\predictive_maintenance\\components\\data_ingestion.py\", line 33, in initiate_data_ingestion\n",
      "    df = read_sql_data()\n",
      "  File \"c:\\Pred_maintainance-Project\\src\\predictive_maintenance\\utils.py\", line 34, in read_sql_data\n",
      "    logging.info(\"Connection establish\",mydb)\n",
      "Message: 'Connection establish'\n",
      "Arguments: (<pymysql.connections.Connection object at 0x0000026158733310>,)\n",
      "c:\\Pred_maintainance-Project\\src\\predictive_maintenance\\utils.py:36: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_train = pd.read_sql_query(\"select * from train1\", mydb)\n",
      "c:\\Pred_maintainance-Project\\src\\predictive_maintenance\\utils.py:38: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_test = pd.read_sql_query(\"select * from test1\", mydb)\n",
      "c:\\Pred_maintainance-Project\\src\\predictive_maintenance\\components\\data_transformation.py:79: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[\"RUL\"][train_df[\"RUL\"]>103]=103\n",
      "c:\\Pred_maintainance-Project\\src\\predictive_maintenance\\components\\data_transformation.py:80: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[\"RUL\"][train_df[\"RUL\"]>103]=103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LinearRegression': -0.3603099860921559, 'SVR': -0.34739561314811795, 'RandomForest': -0.40301097782407536, 'KNN': -0.3924267773231862, 'DecisionTree': -0.43966333584606043, 'GradientBoosting': -0.3892188007858073}\n",
      "\n",
      "**********\n",
      "Best Model is SVR with accuracy : -0.34739561314811795\n",
      "\n",
      "*****\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    data_ingestion = DataIngestion()\n",
    "    train_data, test_data = data_ingestion.initiate_data_ingestion()\n",
    "    \n",
    "    data_transformation = DataTransformation()\n",
    "    train_array, test_array = data_transformation.initiate_data_transformation(train_data, test_data)\n",
    "    \n",
    "    model_trainer = ModelTrainer()\n",
    "    model_trainer.initiate_model_training(train_array, test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
